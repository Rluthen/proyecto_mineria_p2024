{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eliminación de preguntas que no cumplen los criterios\n",
    "Con el dataset limpio, podemos comenzar a realizar un análisis utilizando algunas técnicas de NLP para eliminar aquellas preguntas que no cumplan con los criterios del INE establecidos en el punto\n",
    "\n",
    "El resultado de este paso serán:\n",
    "- Un archivo que contenga el texto de las preguntas que no cumplen los criterios y una breve explicación de porqué no está cumpliéndolos (discurso de odio, violencia, malas palabras, etc.)\n",
    "\n",
    "- Un archivo con las preguntas restantes (los campos serán los mismos que en el punto 3.1)\n",
    "\n",
    "- ID del registro\n",
    "\n",
    "- Entidad de Origen\n",
    "\n",
    "- Edad\n",
    "\n",
    "- Género\n",
    "\n",
    "- Identificación con algún grupo en situación de discriminación\n",
    "\n",
    "- Tema de la pregunta\n",
    "\n",
    "- Texto de la pregunta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pysentimiento\n",
      "  Downloading pysentimiento-0.7.3-py3-none-any.whl (39 kB)\n",
      "Collecting datasets>=2.10.1\n",
      "  Downloading datasets-2.19.0-py3-none-any.whl (542 kB)\n",
      "Collecting emoji>=1.6.1\n",
      "  Downloading emoji-2.11.1-py2.py3-none-any.whl (433 kB)\n",
      "Collecting transformers>=4.13.0\n",
      "  Downloading transformers-4.40.1-py3-none-any.whl (9.0 MB)\n",
      "Collecting torch!=2.0.1,>=2.0.0\n",
      "  Downloading torch-2.3.0-cp38-cp38-win_amd64.whl (159.8 MB)\n",
      "Collecting accelerate>=0.27.2\n",
      "  Downloading accelerate-0.29.3-py3-none-any.whl (297 kB)\n",
      "Collecting spacy>=3.5.0\n",
      "  Downloading spacy-3.7.4-cp38-cp38-win_amd64.whl (12.5 MB)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\anaconda\\lib\\site-packages (from accelerate>=0.27.2->pysentimiento) (20.9)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\anaconda\\lib\\site-packages (from accelerate>=0.27.2->pysentimiento) (1.20.1)\n",
      "Collecting huggingface-hub\n",
      "  Downloading huggingface_hub-0.22.2-py3-none-any.whl (388 kB)\n",
      "Requirement already satisfied: pyyaml in d:\\anaconda\\lib\\site-packages (from accelerate>=0.27.2->pysentimiento) (5.4.1)\n",
      "Requirement already satisfied: psutil in d:\\anaconda\\lib\\site-packages (from accelerate>=0.27.2->pysentimiento) (5.8.0)\n",
      "Collecting safetensors>=0.3.1\n",
      "  Downloading safetensors-0.4.3-cp38-none-win_amd64.whl (286 kB)\n",
      "Collecting aiohttp\n",
      "  Downloading aiohttp-3.9.5-cp38-cp38-win_amd64.whl (373 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0\n",
      "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Collecting pyarrow>=12.0.0\n",
      "  Downloading pyarrow-16.0.0-cp38-cp38-win_amd64.whl (25.9 MB)\n",
      "Collecting multiprocess\n",
      "  Downloading multiprocess-0.70.16-py38-none-any.whl (132 kB)\n",
      "Requirement already satisfied: pandas in d:\\anaconda\\lib\\site-packages (from datasets>=2.10.1->pysentimiento) (1.2.4)\n",
      "Collecting tqdm>=4.62.1\n",
      "  Downloading tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
      "Collecting pyarrow-hotfix\n",
      "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
      "Collecting fsspec[http]<=2024.3.1,>=2023.1.0\n",
      "  Downloading fsspec-2024.3.1-py3-none-any.whl (171 kB)\n",
      "Collecting xxhash\n",
      "  Downloading xxhash-3.4.1-cp38-cp38-win_amd64.whl (29 kB)\n",
      "Requirement already satisfied: requests>=2.19.0 in d:\\anaconda\\lib\\site-packages (from datasets>=2.10.1->pysentimiento) (2.25.1)\n",
      "Requirement already satisfied: filelock in d:\\anaconda\\lib\\site-packages (from datasets>=2.10.1->pysentimiento) (3.0.12)\n",
      "Collecting async-timeout<5.0,>=4.0\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.5-cp38-cp38-win_amd64.whl (28 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.4.1-cp38-cp38-win_amd64.whl (50 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\anaconda\\lib\\site-packages (from aiohttp->datasets>=2.10.1->pysentimiento) (20.3.0)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.9.4-cp38-cp38-win_amd64.whl (77 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\anaconda\\lib\\site-packages (from huggingface-hub->accelerate>=0.27.2->pysentimiento) (3.7.4.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in d:\\anaconda\\lib\\site-packages (from packaging>=20.0->accelerate>=0.27.2->pysentimiento) (2.4.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests>=2.19.0->datasets>=2.10.1->pysentimiento) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests>=2.19.0->datasets>=2.10.1->pysentimiento) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests>=2.19.0->datasets>=2.10.1->pysentimiento) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in d:\\anaconda\\lib\\site-packages (from requests>=2.19.0->datasets>=2.10.1->pysentimiento) (4.0.0)\n",
      "Requirement already satisfied: jinja2 in d:\\anaconda\\lib\\site-packages (from spacy>=3.5.0->pysentimiento) (2.11.3)\n",
      "Collecting langcodes<4.0.0,>=3.2.0\n",
      "  Downloading langcodes-3.4.0-py3-none-any.whl (182 kB)\n",
      "Collecting weasel<0.4.0,>=0.1.0\n",
      "  Downloading weasel-0.3.4-py3-none-any.whl (50 kB)\n",
      "Collecting thinc<8.3.0,>=8.2.2\n",
      "  Downloading thinc-8.2.3-cp38-cp38-win_amd64.whl (1.5 MB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Downloading murmurhash-1.0.10-cp38-cp38-win_amd64.whl (25 kB)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4\n",
      "  Downloading pydantic-2.7.1-py3-none-any.whl (409 kB)\n",
      "Requirement already satisfied: setuptools in d:\\anaconda\\lib\\site-packages (from spacy>=3.5.0->pysentimiento) (52.0.0.post20210125)\n",
      "Collecting typer<0.10.0,>=0.3.0\n",
      "  Downloading typer-0.9.4-py3-none-any.whl (45 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Downloading preshed-3.0.9-cp38-cp38-win_amd64.whl (122 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1\n",
      "  Downloading wasabi-1.1.2-py3-none-any.whl (27 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6\n",
      "  Downloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0\n",
      "  Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Collecting smart-open<7.0.0,>=5.2.1\n",
      "  Downloading smart_open-6.4.0-py3-none-any.whl (57 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Downloading cymem-2.0.8-cp38-cp38-win_amd64.whl (39 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3\n",
      "  Downloading srsly-2.4.8-cp38-cp38-win_amd64.whl (483 kB)\n",
      "Collecting language-data>=1.2\n",
      "  Downloading language_data-1.2.0-py3-none-any.whl (5.4 MB)\n",
      "Collecting marisa-trie>=0.7.7\n",
      "  Downloading marisa_trie-1.1.0-cp38-cp38-win_amd64.whl (152 kB)\n",
      "Collecting pydantic-core==2.18.2\n",
      "  Downloading pydantic_core-2.18.2-cp38-none-win_amd64.whl (1.9 MB)\n",
      "Collecting typing-extensions>=3.7.4.3\n",
      "  Downloading typing_extensions-4.11.0-py3-none-any.whl (34 kB)\n",
      "Collecting annotated-types>=0.4.0\n",
      "  Downloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Collecting blis<0.8.0,>=0.7.8\n",
      "  Downloading blis-0.7.11-cp38-cp38-win_amd64.whl (6.6 MB)\n",
      "Collecting confection<1.0.0,>=0.0.1\n",
      "  Downloading confection-0.1.4-py3-none-any.whl (35 kB)\n",
      "Requirement already satisfied: networkx in d:\\anaconda\\lib\\site-packages (from torch!=2.0.1,>=2.0.0->pysentimiento) (2.5)\n",
      "Collecting mkl<=2021.4.0,>=2021.1.1\n",
      "  Downloading mkl-2021.4.0-py2.py3-none-win_amd64.whl (228.5 MB)\n",
      "Requirement already satisfied: sympy in d:\\anaconda\\lib\\site-packages (from torch!=2.0.1,>=2.0.0->pysentimiento) (1.8)\n",
      "Collecting intel-openmp==2021.*\n",
      "  Downloading intel_openmp-2021.4.0-py2.py3-none-win_amd64.whl (3.5 MB)\n",
      "Collecting tbb==2021.*\n",
      "  Downloading tbb-2021.12.0-py3-none-win_amd64.whl (286 kB)\n",
      "Requirement already satisfied: colorama in d:\\anaconda\\lib\\site-packages (from tqdm>=4.62.1->datasets>=2.10.1->pysentimiento) (0.4.4)\n",
      "Collecting tokenizers<0.20,>=0.19\n",
      "  Downloading tokenizers-0.19.1-cp38-none-win_amd64.whl (2.2 MB)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\anaconda\\lib\\site-packages (from transformers>=4.13.0->pysentimiento) (2021.4.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in d:\\anaconda\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy>=3.5.0->pysentimiento) (7.1.2)\n",
      "Collecting colorama\n",
      "  Using cached colorama-0.4.6-py2.py3-none-any.whl (25 kB)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pylint 2.7.4 requires astroid<2.7,>=2.5.2, but you have astroid 2.5 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collecting cloudpathlib<0.17.0,>=0.7.0\n",
      "  Downloading cloudpathlib-0.16.0-py3-none-any.whl (45 kB)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in d:\\anaconda\\lib\\site-packages (from jinja2->spacy>=3.5.0->pysentimiento) (1.1.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in d:\\anaconda\\lib\\site-packages (from networkx->torch!=2.0.1,>=2.0.0->pysentimiento) (5.0.6)\n",
      "Requirement already satisfied: pytz>=2017.3 in d:\\anaconda\\lib\\site-packages (from pandas->datasets>=2.10.1->pysentimiento) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in d:\\anaconda\\lib\\site-packages (from pandas->datasets>=2.10.1->pysentimiento) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in d:\\anaconda\\lib\\site-packages (from python-dateutil>=2.7.3->pandas->datasets>=2.10.1->pysentimiento) (1.15.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in d:\\anaconda\\lib\\site-packages (from sympy->torch!=2.0.1,>=2.0.0->pysentimiento) (1.2.1)\n",
      "Installing collected packages: typing-extensions, pydantic-core, multidict, frozenlist, colorama, catalogue, annotated-types, yarl, tqdm, tbb, srsly, pydantic, murmurhash, marisa-trie, intel-openmp, fsspec, cymem, async-timeout, aiosignal, wasabi, typer, smart-open, preshed, mkl, language-data, huggingface-hub, dill, confection, cloudpathlib, blis, aiohttp, xxhash, weasel, torch, tokenizers, thinc, spacy-loggers, spacy-legacy, safetensors, pyarrow-hotfix, pyarrow, multiprocess, langcodes, transformers, spacy, emoji, datasets, accelerate, pysentimiento\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 3.7.4.3\n",
      "    Uninstalling typing-extensions-3.7.4.3:\n",
      "      Successfully uninstalled typing-extensions-3.7.4.3\n",
      "  Attempting uninstall: colorama\n",
      "    Found existing installation: colorama 0.4.4\n",
      "    Uninstalling colorama-0.4.4:\n",
      "      Successfully uninstalled colorama-0.4.4\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.59.0\n",
      "    Uninstalling tqdm-4.59.0:\n",
      "      Successfully uninstalled tqdm-4.59.0\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 0.9.0\n",
      "    Uninstalling fsspec-0.9.0:\n",
      "      Successfully uninstalled fsspec-0.9.0\n",
      "Successfully installed accelerate-0.29.3 aiohttp-3.9.5 aiosignal-1.3.1 annotated-types-0.6.0 async-timeout-4.0.3 blis-0.7.11 catalogue-2.0.10 cloudpathlib-0.16.0 colorama-0.4.6 confection-0.1.4 cymem-2.0.8 datasets-2.19.0 dill-0.3.8 emoji-2.11.1 frozenlist-1.4.1 fsspec-2024.3.1 huggingface-hub-0.22.2 intel-openmp-2021.4.0 langcodes-3.4.0 language-data-1.2.0 marisa-trie-1.1.0 mkl-2021.4.0 multidict-6.0.5 multiprocess-0.70.16 murmurhash-1.0.10 preshed-3.0.9 pyarrow-16.0.0 pyarrow-hotfix-0.6 pydantic-2.7.1 pydantic-core-2.18.2 pysentimiento-0.7.3 safetensors-0.4.3 smart-open-6.4.0 spacy-3.7.4 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.4.8 tbb-2021.12.0 thinc-8.2.3 tokenizers-0.19.1 torch-2.3.0 tqdm-4.66.2 transformers-4.40.1 typer-0.9.4 typing-extensions-4.11.0 wasabi-1.1.2 weasel-0.3.4 xxhash-3.4.1 yarl-1.9.4\n"
     ]
    }
   ],
   "source": [
    "!pip install pysentimiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¿Cuando van a dejar de permitir que los extranjeros y migrantes ataquen a los mexicanos en su propia casa?\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['¿Cuando van a dejar de permitir que los extranjeros y migrantes ataquen a los mexicanos en su propia casa?'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-e986dac3837b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./preguntas_rechazadas.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'a'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0marchivo\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0marchivo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'La pregunta \"{pregunta}\" fue rechazada por: {analizador}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m       \u001b[0mlimpio_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpregunta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlimpio_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4306\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[1;36m1.0\u001b[0m     \u001b[1;36m0.8\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4307\u001b[0m         \"\"\"\n\u001b[1;32m-> 4308\u001b[1;33m         return super().drop(\n\u001b[0m\u001b[0;32m   4309\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4310\u001b[0m             \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4151\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4152\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4153\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4155\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   4186\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4187\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4188\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4189\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   5589\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5590\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5591\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5592\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5593\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['¿Cuando van a dejar de permitir que los extranjeros y migrantes ataquen a los mexicanos en su propia casa?'] not found in axis\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from pysentimiento import create_analyzer\n",
    "\n",
    "hate_speech_analyzer = create_analyzer(task=\"hate_speech\", lang=\"es\")\n",
    "\n",
    "limpio_df = pd.read_csv('./Base_limpia.csv')\n",
    "\n",
    "for pregunta in limpio_df['pregunta']:\n",
    "    analizador = hate_speech_analyzer.predict(pregunta).output\n",
    "    if len(analizador) > 0:\n",
    "      print(pregunta)\n",
    "      with open('./preguntas_rechazadas.txt', 'a') as archivo:\n",
    "        archivo.write(f'La pregunta \"{pregunta}\" fue rechazada por: {analizador}')\n",
    "      limpio_df = limpio_df[limpio_df['pregunta'] != pregunta]\n",
    "\n",
    "\n",
    "display(limpio_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
